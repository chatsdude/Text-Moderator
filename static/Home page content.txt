User-generated content has become one of the most powerful tools in raising brand recognition and customer trust. It is highly instrumental in influencing the decision-making of customers.
However, the utilization of user-generated content comes with major risks in terms of how it can influence the users’ perspective of the brand. 
How will businesses ensure that their brand is being portrayed accordingly and ensure that their customers are safe from defaming and offensive content?
Estimates vary
widely, but most indicate that more than
100,000 people are moderating content
globally. The work is difficult to stomach.
Attrition is high.

moderators sift through hundreds of examples of distressing content during each eight hour shift.
They assess posts including, but not limited to, depictions of violent death – including suicide and murder – self-harm, assault, violence against animals, hate speech and sexualised violence.

repeated exposure to these types of content has serious consequences.

This is why using AI as an aid for human agents, rather than a replacement, is ideal.

According to the World Economic Forum, by 2025, an estimated 463 exabytes of data will be created each day – that's the equivalent of 2.1 million DVDs. No matter the size or skill of your content moderation team, the sheer quantity of user-generated content makes it difficult for humans to keep pace. There are simply not enough hours in the day!